{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBRQ0yawiPCv"
   },
   "source": [
    "#CafChem Teaching - Transformers demo.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MauricioCafiero/CafChemTeach/blob/main/notebooks/Transformers_demo_CafChem.ipynb)\n",
    "\n",
    "## This notebook allows you to:\n",
    "- See how decoders generate text\n",
    "- See how encoders fill in text.\n",
    "\n",
    "## Requirements:\n",
    "- It will install all needed libraries.\n",
    "- You will need a HuggingFace token saved as a secret\n",
    "- can run a high memory CPU, but using any GPU will greatly increase speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7V0avh4AGWM0",
    "outputId": "f803cb60-3f15-4696-9e1f-d69ec656956c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CafChemTeach'...\n",
      "remote: Enumerating objects: 14, done.\u001b[K\n",
      "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
      "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
      "remote: Total 14 (delta 3), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (14/14), 6.42 KiB | 6.42 MiB/s, done.\n",
      "Resolving deltas: 100% (3/3), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/MauricioCafiero/CafChemTeach.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0vleuu5riCHl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import CafChemTeach.CafChemTeach as cct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NX06984T76-a"
   },
   "source": [
    "## Demonstrate transformer decoder autoregressive inference.\n",
    "- set-up model, tokenizer and device\n",
    "- call for inference\n",
    "- display results\n",
    "- can also call for the top *n* tokens at each step and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "cf892e952f674ec4b960b03df11a11ef",
      "ee07ca4887304c7d8c71aff6ff84e32e",
      "792eaf60c00e48ea8ff0df7b28a93753",
      "f4c022fb33ff4ee0b6e61c66c805921b",
      "9f09f021c4684cbeb7da1c84f14154b8",
      "fc1025e3f2814384b6688e9fef4abced",
      "7b47d4290c8f44c4bb096b9adde5690f",
      "0189dbf1efa541a280d984e0d15ec0ea",
      "551d3f4d0e884f7ea03bf7f8670c6d3a",
      "18155a6751034a9d8b4a7582b4a3303f",
      "d2c901a5e1814614905767cfa2df66ff"
     ]
    },
    "id": "_gOyDvMkTRm7",
    "outputId": "f30f2b11-a715-4951-dc7d-9afc95d82243"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf892e952f674ec4b960b03df11a11ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model setup complete: microsoft/Phi-3.5-mini-instruct\n"
     ]
    }
   ],
   "source": [
    "model_name = \"microsoft/Phi-3.5-mini-instruct\"\n",
    "\n",
    "tokenizer, model, device = cct.setup_decoder(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-lIMwn7jUpIr"
   },
   "outputs": [],
   "source": [
    "input_txt = \"what country has the best cuisine?\"\n",
    "iterations = cct.decoder_inference(model, tokenizer,device, input_txt, n_steps= 100,\n",
    "                               TEMP = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejuX2omgWXDa",
    "outputId": "4e257e60-3d56-472d-bd61-422ba9078f22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token               Percent Probability\n",
      "\n",
      "                     34.19%\n",
      "\n",
      "                     80.28%\n",
      "Ch                    2.21%\n",
      "at                    99.97%\n",
      "bot                   98.63%\n",
      ":                     96.43%\n",
      "The                   20.56%\n",
      "appreci               5.16%\n",
      "ation                 100.00%\n",
      "of                    84.75%\n",
      "good                  0.73%\n",
      "cu                    84.55%\n",
      "is                    100.00%\n",
      "ine                   100.00%\n",
      "var                   8.55%\n",
      "ies                   100.00%\n",
      "by                    6.38%\n",
      "individual            54.89%\n",
      "t                     35.00%\n",
      "ast                   99.99%\n",
      "es                    100.00%\n",
      ",                     24.97%\n",
      "as                    2.49%\n",
      "there                 11.80%\n",
      "is                    43.69%\n",
      "no                    93.24%\n",
      "objective             9.60%\n",
      "measure               57.96%\n",
      "of                    30.49%\n",
      "the                   39.02%\n",
      "\"                     72.97%\n",
      "best                  99.98%\n",
      "\"                     55.45%\n",
      "cu                    72.47%\n",
      "is                    100.00%\n",
      "ine                   99.98%\n",
      ".                     61.00%\n",
      "Many                  26.44%\n",
      "cult                  23.06%\n",
      "ures                  99.88%\n",
      "are                   23.67%\n",
      "celebrated            34.62%\n",
      "for                   98.45%\n",
      "their                 98.74%\n",
      "unique                42.46%\n",
      "cul                   17.37%\n",
      "inary                 99.99%\n",
      "trad                  80.58%\n",
      "itions                100.00%\n",
      ",                     20.40%\n",
      "with                  2.90%\n",
      "France                7.00%\n",
      ",                     43.59%\n",
      "Italy                 92.31%\n",
      ",                     99.98%\n",
      "Japan                 66.12%\n",
      ",                     99.95%\n",
      "and                   78.09%\n",
      "Th                    68.25%\n",
      "ailand                99.89%\n",
      "often                 82.73%\n",
      "being                 18.18%\n",
      "held                  1.11%\n",
      "in                    96.68%\n",
      "high                  99.16%\n",
      "regard                88.86%\n",
      "for                   60.72%\n",
      "their                 98.20%\n",
      "influ                 2.85%\n",
      "ential                99.78%\n",
      "g                     15.45%\n",
      "astr                  98.08%\n",
      "onom                  94.58%\n",
      "ies                   66.84%\n",
      ".                     97.68%\n",
      "If                    12.34%\n",
      "you                   98.36%\n",
      "'                     78.25%\n",
      "re                    88.01%\n",
      "interested            78.81%\n",
      "in                    50.07%\n",
      "discover              1.62%\n",
      "ing                   100.00%\n",
      "cu                    2.09%\n",
      "is                    100.00%\n",
      "ines                  93.36%\n",
      "from                  59.79%\n",
      "specific              16.17%\n",
      "countries             71.48%\n",
      ",                     80.97%\n",
      "I                     98.31%\n",
      "can                   76.09%\n",
      "provide               39.06%\n",
      "more                  14.41%\n",
      "information           53.06%\n",
      "about                 12.70%\n",
      "a                     1.54%\n",
      "particular            62.97%\n",
      "locale                0.13%\n",
      "'                     69.55%\n"
     ]
    }
   ],
   "source": [
    "cct.display_autoregression(iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwykxh0cW35g",
    "outputId": "baad3b1e-e1d1-4049-a7d1-169250899b11"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/CafChemTeach/CafChemTeach.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_id.append(torch.tensor(topk).cuda())\n",
      "/content/CafChemTeach/CafChemTeach.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_id.append(torch.tensor(topk).cuda())\n",
      "/content/CafChemTeach/CafChemTeach.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_id.append(torch.tensor(topk).cuda())\n",
      "/content/CafChemTeach/CafChemTeach.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_id.append(torch.tensor(topk).cuda())\n",
      "/content/CafChemTeach/CafChemTeach.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_id.append(torch.tensor(topk).cuda())\n",
      "/content/CafChemTeach/CafChemTeach.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_id.append(torch.tensor(topk).cuda())\n",
      "/content/CafChemTeach/CafChemTeach.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_id.append(torch.tensor(topk).cuda())\n",
      "/content/CafChemTeach/CafChemTeach.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_id.append(torch.tensor(topk).cuda())\n",
      "/content/CafChemTeach/CafChemTeach.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_id.append(torch.tensor(topk).cuda())\n",
      "/content/CafChemTeach/CafChemTeach.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_id.append(torch.tensor(topk).cuda())\n"
     ]
    }
   ],
   "source": [
    "prob_iterations = cct.decoder_list_probs(model, tokenizer,device, input_txt, n_steps= 100,\n",
    "                               TEMP = 1.0, number_to_return = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oTZGWU3e4d4G",
    "outputId": "8a5e3b53-ced7-4084-cf3e-294164873dd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Tokens and probabilities for step 0 =========\n",
      "The: 7.323189079761505\n",
      "It: 8.994079381227493\n",
      "This: 10.452038049697876\n",
      "\n",
      ": 34.18930172920227\n",
      "========= Tokens and probabilities for step 1 =========\n",
      "This: 1.0201356373727322\n",
      "The: 1.1555506847798824\n",
      "A: 2.6561640202999115\n",
      "\n",
      ": 80.27666211128235\n",
      "========= Tokens and probabilities for step 2 =========\n",
      "Ass: 4.4883981347084045\n",
      "A: 5.07400669157505\n",
      "Answer: 8.118794113397598\n",
      "#: 18.051128089427948\n",
      "========= Tokens and probabilities for step 3 =========\n",
      "Response: 0.3185216337442398\n",
      "Comple: 0.4733067471534014\n",
      ": 5.073525384068489\n",
      "Answer: 92.40642189979553\n",
      "========= Tokens and probabilities for step 4 =========\n",
      "The: 0.050070928409695625\n",
      ":: 1.777053065598011\n",
      ": 2.5199273601174355\n",
      "\n",
      ": 95.26922702789307\n",
      "========= Tokens and probabilities for step 5 =========\n",
      "\n",
      ": 0.8449164219200611\n",
      "It: 3.1101729720830917\n",
      "The: 3.8140229880809784\n",
      "Det: 90.22757411003113\n",
      "========= Tokens and probabilities for step 6 =========\n",
      "aching: 1.2448851727242527e-06\n",
      "ract: 2.436488344415011e-06\n",
      "ect: 2.389942324043659e-05\n",
      "erm: 99.99997615814209\n",
      "========= Tokens and probabilities for step 7 =========\n",
      "ination: 0.00025547697077854536\n",
      "in: 0.0002906857162088272\n",
      "ing: 0.00031877207220532\n",
      "ining: 99.9988317489624\n",
      "========= Tokens and probabilities for step 8 =========\n",
      "a: 0.25860590394586325\n",
      "\": 2.3430492728948593\n",
      "the: 28.66705060005188\n",
      "which: 68.68793368339539\n",
      "========= Tokens and probabilities for step 9 =========\n",
      "cu: 0.0003123595433862647\n",
      "one: 0.00047358466872537974\n",
      "single: 0.0008143728337017819\n",
      "country: 99.99725818634033\n",
      "========= Tokens and probabilities for step 10 =========\n",
      "': 0.0099698401754722\n",
      "\": 0.010359166481066495\n",
      "poss: 0.015753057959955186\n",
      "has: 99.95526671409607\n",
      "========= Tokens and probabilities for step 11 =========\n",
      "“: 0.003845197716145776\n",
      "': 0.026147864991798997\n",
      "\": 5.5473677814006805\n",
      "the: 94.42192316055298\n",
      "========= Tokens and probabilities for step 12 =========\n",
      "“: 0.11862657265737653\n",
      "': 0.60724844224751\n",
      "best: 5.84714338183403\n",
      "\": 93.41681599617004\n",
      "========= Tokens and probabilities for step 13 =========\n",
      "Best: 9.225178132510337e-05\n",
      "the: 0.00027790254080173327\n",
      "bet: 0.0016789743312983774\n",
      "best: 99.99780654907227\n",
      "========= Tokens and probabilities for step 14 =========\n",
      ",\": 9.334871151622792e-05\n",
      "”: 0.0008506799531460274\n",
      "cu: 0.22494252771139145\n",
      "\": 99.77401494979858\n",
      "========= Tokens and probabilities for step 15 =========\n",
      "national: 8.299855380755616e-05\n",
      "cul: 0.0005560711088037351\n",
      "food: 0.012941136083099991\n",
      "cu: 99.98629093170166\n",
      "========= Tokens and probabilities for step 16 =========\n",
      "ison: 9.529522310147698e-09\n",
      "inary: 2.0972158731868973e-08\n",
      "ine: 1.2088790413145034e-05\n",
      "is: 99.99998807907104\n",
      "========= Tokens and probabilities for step 17 =========\n",
      "ure: 5.863814642181886e-10\n",
      "INE: 6.529716004011199e-10\n",
      "ines: 6.225243431856597e-07\n",
      "ine: 100.0\n",
      "========= Tokens and probabilities for step 18 =========\n",
      "involves: 0.01697530533419922\n",
      "depends: 0.05292618297971785\n",
      "can: 4.094474017620087\n",
      "is: 95.7789659500122\n",
      "========= Tokens and probabilities for step 19 =========\n",
      "inher: 0.8895494975149632\n",
      "a: 3.4074433147907257\n",
      "subject: 35.88259220123291\n",
      "highly: 58.66038203239441\n",
      "========= Tokens and probabilities for step 20 =========\n",
      "challeng: 1.9332622969159274e-05\n",
      "dependent: 2.746567133726785e-05\n",
      "deb: 7.201102789622382e-05\n",
      "subject: 99.99984502792358\n",
      "========= Tokens and probabilities for step 21 =========\n",
      "matter: 2.710007107609158e-07\n",
      "iv: 5.0636352888489e-07\n",
      "to: 1.0138470685205903e-05\n",
      "ive: 99.99998807907104\n",
      "========= Tokens and probabilities for step 22 =========\n",
      "since: 0.28690609615296125\n",
      "as: 15.37352204322815\n",
      ",: 22.31941670179367\n",
      "and: 61.81753873825073\n",
      "========= Tokens and probabilities for step 23 =========\n",
      "dependent: 2.831569127738476\n",
      "can: 9.47665274143219\n",
      "var: 27.005434036254883\n",
      "depends: 51.376694440841675\n",
      "========= Tokens and probabilities for step 24 =========\n",
      "upon: 0.09382618009112775\n",
      "largely: 0.10414136340841651\n",
      "greatly: 0.7812725380063057\n",
      "on: 98.96547794342041\n",
      "========= Tokens and probabilities for step 25 =========\n",
      "cultural: 1.9915835931897163\n",
      "various: 5.66130056977272\n",
      "personal: 39.81689810752869\n",
      "individual: 50.74004530906677\n",
      "========= Tokens and probabilities for step 26 =========\n",
      "pal: 0.25507472455501556\n",
      "prefer: 13.911475241184235\n",
      "taste: 23.902827501296997\n",
      "t: 61.73018217086792\n",
      "========= Tokens and probabilities for step 27 =========\n",
      "aster: 3.2613947098525387e-06\n",
      "asted: 1.6362649546408647e-05\n",
      "aste: 1.9811309925898968e-05\n",
      "ast: 99.99995231628418\n",
      "========= Tokens and probabilities for step 28 =========\n",
      "ers: 3.074330265917524e-05\n",
      "ings: 4.878757522419619e-05\n",
      "prefer: 6.101745384512469e-05\n",
      "es: 99.99979734420776\n",
      "========= Tokens and probabilities for step 29 =========\n",
      "as: 0.0492470629978925\n",
      ".: 0.2620846265926957\n",
      "and: 6.820350885391235\n",
      ",: 92.8537368774414\n",
      "========= Tokens and probabilities for step 30 =========\n",
      "cul: 0.3143849316984415\n",
      "personal: 0.5500982515513897\n",
      "prefer: 0.7471032906323671\n",
      "cultural: 97.61783480644226\n",
      "========= Tokens and probabilities for step 31 =========\n",
      "influ: 6.952260434627533\n",
      "appreci: 12.463248521089554\n",
      "background: 28.166833519935608\n",
      "prefer: 28.62851917743683\n",
      "========= Tokens and probabilities for step 32 =========\n",
      "encies: 1.6077933651104104e-06\n",
      "ances: 2.9316037597482136e-06\n",
      "enses: 3.7269831665298625e-06\n",
      "ences: 99.99998807907104\n",
      "========= Tokens and probabilities for step 33 =========\n",
      "or: 8.379031157801364e-06\n",
      "as: 2.4647735585858754e-05\n",
      "and: 0.009478090214543045\n",
      ",: 99.99047517776489\n",
      "========= Tokens and probabilities for step 34 =========\n",
      "di: 0.430215522646904\n",
      "cul: 1.1742928996682167\n",
      "personal: 1.5789123252034187\n",
      "and: 96.0070252418518\n",
      "========= Tokens and probabilities for step 35 =========\n",
      "the: 3.839217498898506\n",
      "cul: 11.023828387260437\n",
      "criteria: 16.03682190179825\n",
      "personal: 54.345911741256714\n",
      "========= Tokens and probabilities for step 36 =========\n",
      "criteria: 0.5140603054314852\n",
      "opinions: 0.9355991147458553\n",
      "experience: 1.1057661846280098\n",
      "experiences: 95.53132057189941\n",
      "========= Tokens and probabilities for step 37 =========\n",
      "in: 0.028969108825549483\n",
      ",: 0.05567435873672366\n",
      "with: 12.172757089138031\n",
      ".: 87.6928448677063\n",
      "========= Tokens and probabilities for step 38 =========\n",
      "Each: 4.805520549416542\n",
      "D: 5.156043171882629\n",
      "Food: 12.109731137752533\n",
      "C: 60.142695903778076\n",
      "========= Tokens and probabilities for step 39 =========\n",
      "riteria: 0.0010139801815967076\n",
      "ele: 0.0015826226444914937\n",
      "ul: 1.8889660015702248\n",
      "uis: 98.10608625411987\n",
      "========= Tokens and probabilities for step 40 =========\n",
      "inity: 0.0004244368028594181\n",
      "inen: 0.0007569609351776307\n",
      "ines: 15.961353480815887\n",
      "ine: 84.03493762016296\n",
      "========= Tokens and probabilities for step 41 =========\n",
      "reflect: 4.400600120425224\n",
      "var: 9.909946471452713\n",
      "can: 12.672743201255798\n",
      "is: 59.60844159126282\n",
      "========= Tokens and probabilities for step 42 =========\n",
      "often: 12.140118330717087\n",
      "an: 16.498394310474396\n",
      "deeply: 31.520801782608032\n",
      "a: 35.704395174980164\n",
      "========= Tokens and probabilities for step 43 =========\n",
      "complex: 1.6162453219294548\n",
      "deeply: 1.7986005172133446\n",
      "form: 2.5873973965644836\n",
      "reflection: 82.88366198539734\n",
      "========= Tokens and probabilities for step 44 =========\n",
      "both: 5.1632537179102656e-05\n",
      "and: 0.00017696704617264913\n",
      "not: 0.0009565288564772345\n",
      "of: 99.99879598617554\n",
      "========= Tokens and probabilities for step 45 =========\n",
      "its: 1.7042255029082298\n",
      "history: 2.3174701258540154\n",
      "the: 4.337572678923607\n",
      "a: 87.0278000831604\n",
      "========= Tokens and probabilities for step 46 =========\n",
      "place: 0.8533898741006851\n",
      "nation: 6.700611859560013\n",
      "country: 38.54994475841522\n",
      "region: 52.66178846359253\n",
      "========= Tokens and probabilities for step 47 =========\n",
      ",: 0.001197753954329528\n",
      "or: 0.05909920437261462\n",
      "’: 0.9142824448645115\n",
      "': 99.02442693710327\n",
      "========= Tokens and probabilities for step 48 =========\n",
      "sf: 6.492502646615605e-08\n",
      "S: 1.1843668268340934e-06\n",
      "s: 100.0\n",
      "========= Tokens and probabilities for step 49 =========\n",
      "cultural: 3.204568102955818\n",
      "ge: 3.3364079892635345\n",
      "culture: 28.057152032852173\n",
      "history: 61.71528100967407\n",
      "========= Tokens and probabilities for step 50 =========\n",
      ";: 1.6890139420411288e-05\n",
      "(: 2.236931351262683e-05\n",
      "and: 0.005468268500408158\n",
      ",: 99.99442100524902\n",
      "========= Tokens and probabilities for step 51 =========\n",
      "trad: 1.738159917294979\n",
      "culture: 13.547399640083313\n",
      "climate: 20.120912790298462\n",
      "ge: 59.653204679489136\n",
      "========= Tokens and probabilities for step 52 =========\n",
      "ology: 0.006774120265617967\n",
      "ographic: 0.03903683682437986\n",
      "ographical: 0.48400871455669403\n",
      "ography: 99.46807026863098\n",
      "========= Tokens and probabilities for step 53 =========\n",
      "influ: 2.3070125365620697e-06\n",
      "(: 6.081070864638605e-05\n",
      "and: 0.0002166239937650971\n",
      ",: 99.99971389770508\n",
      "========= Tokens and probabilities for step 54 =========\n",
      "cultural: 4.699747636914253\n",
      "and: 21.52860164642334\n",
      "climate: 24.066871404647827\n",
      "culture: 38.48854601383209\n",
      "========= Tokens and probabilities for step 55 =========\n",
      "trad: 1.4564116668225324e-05\n",
      "practices: 2.102094498468432e-05\n",
      "and: 0.0030714872991666198\n",
      ",: 99.99682903289795\n",
      "========= Tokens and probabilities for step 56 =========\n",
      "climate: 0.19754483364522457\n",
      "econom: 0.23805557284504175\n",
      "trad: 0.40597631596028805\n",
      "and: 98.5292136669159\n",
      "========= Tokens and probabilities for step 57 =========\n",
      "the: 6.177594140172005\n",
      "tradition: 10.385025292634964\n",
      "trad: 26.400792598724365\n",
      "available: 31.469139456748962\n",
      "========= Tokens and probabilities for step 58 =========\n",
      "produce: 0.0938831886742264\n",
      "local: 0.223406869918108\n",
      "resources: 29.859957098960876\n",
      "ing: 69.76896524429321\n",
      "========= Tokens and probabilities for step 59 =========\n",
      "est: 7.989737205171821e-08\n",
      "er: 2.9532316592195684e-07\n",
      "enu: 2.0651219756473438e-05\n",
      "red: 99.99997615814209\n",
      "========= Tokens and probabilities for step 60 =========\n",
      "ientes: 6.281076707637112e-05\n",
      "ient: 0.00043893269321415573\n",
      "iens: 0.002687732376216445\n",
      "ients: 99.9967098236084\n",
      "========= Tokens and probabilities for step 61 =========\n",
      "and: 0.26022656820714474\n",
      ";: 0.2861826214939356\n",
      ".: 25.584471225738525\n",
      ",: 73.77570271492004\n",
      "========= Tokens and probabilities for step 62 =========\n",
      "which: 9.99554619193077\n",
      "so: 10.181887447834015\n",
      "and: 17.753174901008606\n",
      "making: 54.22372817993164\n",
      "========= Tokens and probabilities for step 63 =========\n",
      "its: 0.5060833878815174\n",
      "every: 5.981782078742981\n",
      "each: 17.183467745780945\n",
      "it: 74.45843815803528\n",
      "========= Tokens and probabilities for step 64 =========\n",
      "deeply: 5.922980979084969\n",
      "uniqu: 7.522879540920258\n",
      "a: 14.319494366645813\n",
      "unique: 50.98826885223389\n",
      "========= Tokens and probabilities for step 65 =========\n",
      "in: 1.033485122025013\n",
      ".: 3.0101511627435684\n",
      "to: 17.105400562286377\n",
      "and: 78.63907814025879\n",
      "========= Tokens and probabilities for step 66 =========\n",
      "cher: 5.972519144415855\n",
      "varied: 8.739665150642395\n",
      "special: 9.572754800319672\n",
      "diverse: 46.433210372924805\n",
      "========= Tokens and probabilities for step 67 =========\n",
      "world: 4.221610352396965\n",
      "around: 17.98507422208786\n",
      ".: 32.57322311401367\n",
      "across: 43.19796562194824\n",
      "========= Tokens and probabilities for step 68 =========\n",
      "countries: 0.11418214999139309\n",
      "various: 0.13490845449268818\n",
      "different: 8.887232840061188\n",
      "the: 90.83046913146973\n",
      "========= Tokens and probabilities for step 69 =========\n",
      "planet: 0.007663952419534326\n",
      "global: 0.014996649406384677\n",
      "glo: 39.59501087665558\n",
      "world: 60.378408432006836\n",
      "========= Tokens and probabilities for step 70 =========\n",
      "with: 0.00380737692466937\n",
      ":: 0.18516872078180313\n",
      "': 0.19467351958155632\n",
      ".: 99.61073994636536\n",
      "========= Tokens and probabilities for step 71 =========\n",
      ": 0.8606176823377609\n",
      "Some: 18.634916841983795\n",
      "\n",
      ": 35.13762354850769\n",
      "Here: 41.94976091384888\n",
      "========= Tokens and probabilities for step 72 =========\n",
      ",: 0.012196597526781261\n",
      "is: 0.26341418270021677\n",
      "': 0.3363469149917364\n",
      "are: 99.37822222709656\n",
      "========= Tokens and probabilities for step 73 =========\n",
      "few: 0.06530389655381441\n",
      "several: 17.12711751461029\n",
      "a: 39.811715483665466\n",
      "some: 42.72444546222687\n",
      "========= Tokens and probabilities for step 74 =========\n",
      "reasons: 0.9716473519802094\n",
      "of: 1.0773222893476486\n",
      "notable: 1.142803393304348\n",
      "countries: 92.31300950050354\n",
      "========= Tokens and probabilities for step 75 =========\n",
      "frequently: 2.763422019779682\n",
      "that: 12.80374526977539\n",
      "ren: 34.001582860946655\n",
      "often: 39.96855318546295\n",
      "========= Tokens and probabilities for step 76 =========\n",
      "la: 0.8837630040943623\n",
      "recognized: 1.7977019771933556\n",
      "pra: 4.468405619263649\n",
      "celebrated: 90.813809633255\n",
      "========= Tokens and probabilities for step 77 =========\n",
      "world: 0.042472517816349864\n",
      "and: 0.04992320900782943\n",
      "glob: 0.08863217080943286\n",
      "for: 99.72042441368103\n",
      "========= Tokens and probabilities for step 78 =========\n",
      "distinct: 0.009357070666737854\n",
      "having: 0.009660874638939276\n",
      "exception: 0.014761561760678887\n",
      "their: 99.93147850036621\n",
      "========= Tokens and probabilities for step 79 =========\n",
      "distinct: 9.969247877597809\n",
      "rich: 14.371991157531738\n",
      "cu: 21.563558280467987\n",
      "cul: 32.24945366382599\n",
      "========= Tokens and probabilities for step 80 =========\n",
      "min: 1.7838436505712707e-06\n",
      "inar: 1.1383206555137804e-05\n",
      "in: 0.0010306600415788125\n",
      "inary: 99.99895095825195\n",
      "========= Tokens and probabilities for step 81 =========\n",
      "her: 7.091125845909119\n",
      "arts: 10.108092427253723\n",
      "trad: 30.648785829544067\n",
      "excell: 31.980520486831665\n",
      "========= Tokens and probabilities for step 82 =========\n",
      "ency: 4.6535569708794355e-05\n",
      "encies: 9.923470543071744e-05\n",
      "ences: 0.003295856367913075\n",
      "ence: 99.99653100967407\n",
      "========= Tokens and probabilities for step 83 =========\n",
      "that: 0.09771342156454921\n",
      "and: 2.3173609748482704\n",
      ",: 10.958433896303177\n",
      ":: 86.06268167495728\n",
      "========= Tokens and probabilities for step 84 =========\n",
      "Japan: 0.00016077153759397333\n",
      "Italy: 0.0009714683073980268\n",
      ": 0.008676655124872923\n",
      "\n",
      ": 99.98987913131714\n",
      "========= Tokens and probabilities for step 85 =========\n",
      " : 0.00017711863620206714\n",
      ": 0.00036052138057129923\n",
      "1: 0.00038659713936795015\n",
      "\n",
      ": 99.99897480010986\n",
      "========= Tokens and probabilities for step 86 =========\n",
      "France: 0.0013599005797004793\n",
      "**: 0.0156063397298567\n",
      "-: 0.12183341896161437\n",
      "1: 99.8581051826477\n",
      "========= Tokens and probabilities for step 87 =========\n",
      "\\.: 8.769634263217085e-06\n",
      "️: 1.0125139482397572e-05\n",
      "): 0.0006591627425223123\n",
      ".: 99.99924898147583\n",
      "========= Tokens and probabilities for step 88 =========\n",
      "Japan: 0.13325553154572845\n",
      "France: 0.52553815767169\n",
      "Italy: 3.22892926633358\n",
      "**: 96.0981011390686\n",
      "========= Tokens and probabilities for step 89 =========\n",
      "Th: 0.070658273762092\n",
      "J: 1.3228585943579674\n",
      "France: 18.43937188386917\n",
      "Ital: 79.99194264411926\n",
      "========= Tokens and probabilities for step 90 =========\n",
      "ina: 1.6417567305637704e-08\n",
      "ia: 2.1504247271764143e-06\n",
      "ian: 0.00012878854249720462\n",
      "y: 99.9998688697815\n",
      "========= Tokens and probabilities for step 91 =========\n",
      "-: 0.007571107562398538\n",
      "(: 0.022377001005224884\n",
      ":: 0.5091642029583454\n",
      "**: 99.45145845413208\n",
      "========= Tokens and probabilities for step 92 =========\n",
      "–: 0.17395971808582544\n",
      "is: 1.0354578495025635\n",
      "-: 6.07890784740448\n",
      ":: 92.58949160575867\n",
      "========= Tokens and probabilities for step 93 =========\n",
      "O: 0.9955856949090958\n",
      "Fam: 3.3961221575737\n",
      "Ren: 17.98110157251358\n",
      "Kn: 72.9529619216919\n",
      "========= Tokens and probabilities for step 94 =========\n",
      "nown: 1.4092998412706947e-05\n",
      "ows: 3.1514133524979115e-05\n",
      "owned: 0.0011849862858070992\n",
      "own: 99.99873638153076\n",
      "========= Tokens and probabilities for step 95 =========\n",
      "as: 0.010341159213567153\n",
      "world: 0.5803526379168034\n",
      "glob: 0.8360458537936211\n",
      "for: 98.55021238327026\n",
      "========= Tokens and probabilities for step 96 =========\n",
      "d: 0.47247083857655525\n",
      "p: 0.5169635638594627\n",
      "past: 2.9417645186185837\n",
      "its: 95.1092779636383\n",
      "========= Tokens and probabilities for step 97 =========\n",
      "simple: 5.388709157705307\n",
      "past: 15.926998853683472\n",
      "rich: 20.069505274295807\n",
      "regional: 44.669392704963684\n",
      "========= Tokens and probabilities for step 98 =========\n",
      "variety: 2.3876575753092766\n",
      "special: 3.550834208726883\n",
      "d: 12.81336396932602\n",
      "divers: 73.84559512138367\n",
      "========= Tokens and probabilities for step 99 =========\n",
      "eness: 0.0007257346624101046\n",
      "ification: 0.0040090515540214255\n",
      "ities: 0.15329160960391164\n",
      "ity: 99.84179735183716\n"
     ]
    }
   ],
   "source": [
    "cct.display_list_probs(prob_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhngrZfo8VXU"
   },
   "source": [
    "## Demonstrate transformer encoder inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lFcsOKmL2-89",
    "outputId": "1f1287d0-e056-437e-cfe7-7597b7c7cbb2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "encoder_tokenizer, encoder_pipe, device = cct.setup_encoder(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_MgLoZQs9tst",
    "outputId": "4b50a3fc-39bd-44f1-e17e-be78430b9bba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked text: After [MASK] I need to go [MASK] the store\n"
     ]
    }
   ],
   "source": [
    "raw_text = \"After work I need to go to the store\"\n",
    "num_to_mask = 2\n",
    "\n",
    "input_txt, mask_idx = cct.mask_text(raw_text, num_to_mask)\n",
    "print(f\"Masked text: {input_txt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vmz0VgEA_Ds9"
   },
   "outputs": [],
   "source": [
    "result = encoder_pipe(input_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hwJeiSKQ_2OH",
    "outputId": "1b439a2c-4a9b-4e7b-ce11-a5bb2ccf9019"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Tokens and probabilities for MASK 1 =========\n",
      "Token: school    , Prob: 23.08\n",
      "Token: dinner    , Prob: 17.81\n",
      "Token: that      , Prob: 17.28\n",
      "Token: work      , Prob:  9.02\n",
      "Token: lunch     , Prob:  8.21\n",
      "========= Tokens and probabilities for MASK 2 =========\n",
      "Token: to        , Prob: 91.08\n",
      "Token: into      , Prob:  4.65\n",
      "Token: through   , Prob:  1.08\n",
      "Token: by        , Prob:  0.82\n",
      "Token: in        , Prob:  0.55\n"
     ]
    }
   ],
   "source": [
    "cct.maskfilling_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T65Jp7nn_b_X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
